# https://grafana.com/docs/grafana/latest/administration/provisioning/#alerting
# https://grafana.com/docs/grafana/latest/alerting/set-up/provision-alerting-resources/file-provisioning
apiVersion: 1

groups:
  - orgId: 1
    name: node_exporter_rules
    folder: node_exporter
    interval: 60s
    rules:
      - uid: reboot_required
        title: Reboot Required
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: 'node_reboot_required > 0'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 0m
        annotations:
          summary: "Reboot required"
          description: "{{ $labels.instance }} requires a reboot."
        labels:
          severity: warn
          receiver: telegram
        isPaused: false
      - uid: instance_high_cpu_usage
        title: Instance High CPU Usage
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: '100 - (avg by (instance, env, service) (rate(node_cpu_seconds_total{mode="idle"}[10m])) * 100) > 90'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 0m
        annotations:
          summary: "CPU usage is at 90%"
          description: "CPU usage is at 90%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        labels:
          severity: error
          receiver: telegram
        isPaused: false
      - uid: instance_ram_space_filling_up
        title: Instance RAM Space Filling Up
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: 'node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 15'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 5m
        annotations:
          summary: "RAM memory has less than 15% space left"
          description: "RAM memory has less than 15% space left\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        labels:
          severity: warn
          receiver: telegram
        isPaused: false
      - uid: instance_ram_out_of_space
        title: Instance RAM Out Of Space
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: 'node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 5'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 5m
        annotations:
          summary: "RAM memory has less than 5% space left"
          description: "RAM memory has less than 5% space left\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        labels:
          severity: error
          receiver: telegram
        isPaused: false
      - uid: instance_filesystem_filling_up_24h
        title: Instance Filesystem Space Filling Up (24h)
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: |
                (
                  node_filesystem_avail_bytes{fstype!=""} / node_filesystem_size_bytes{fstype!=""} * 100 < 40
                and
                  predict_linear(node_filesystem_avail_bytes{fstype!=""}[6h], 24*60*60) < 0
                and
                  node_filesystem_readonly{fstype!=""} == 0
                )
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 1h
        annotations:
          summary: "Filesystem is predicted to run out of space within the next 24 hours"
          description: 'Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left and is filling up.'
        labels:
          severity: warn
          receiver: telegram
        isPaused: false
      - uid: instance_filesystem_filling_up_12h
        title: Instance Filesystem Space Filling Up (12h)
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: |
                (
                  node_filesystem_avail_bytes{fstype!=""} / node_filesystem_size_bytes{fstype!=""} * 100 < 20
                and
                  predict_linear(node_filesystem_avail_bytes{fstype!=""}[6h], 12*60*60) < 0
                and
                  node_filesystem_readonly{fstype!=""} == 0
                )
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 1h
        annotations:
          summary: "Filesystem is predicted to run out of space within the next 12 hours"
          description: 'Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left and is filling up fast.'
        labels:
          severity: error
          receiver: telegram
        isPaused: false
      - uid: instance_filesystem_almost_full
        title: Instance Filesystem Almost Out Of Space
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: |
                (
                  node_filesystem_avail_bytes{fstype!=""} / node_filesystem_size_bytes{fstype!=""} * 100 < 15
                and
                  node_filesystem_readonly{fstype!=""} == 0
                )
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 5m
        annotations:
          summary: "Filesystem has less than 15% space left"
          description: 'Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left.'
        labels:
          severity: warn
          receiver: telegram
        isPaused: false
      - uid: instance_filesystem_out_of_space
        title: Instance Filesystem Out Of Space
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: |
                (
                  node_filesystem_avail_bytes{fstype!=""} / node_filesystem_size_bytes{fstype!=""} * 100 < 5
                and
                  node_filesystem_readonly{fstype!=""} == 0
                )
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 5m
        annotations:
          summary: "Filesystem has less than 5% space left"
          description: 'Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left.'
        labels:
          severity: error
          receiver: telegram
        isPaused: false
      - uid: instance_swap_space_filling_up
        title: Instance Swap Space Filling Up
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: '(1 - (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes)) * 100 > 70'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 2m
        annotations:
          summary: "Swap memory has less than 30% space left"
          description: "Swap memory has less than 30% space left\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        labels:
          severity: warn
          receiver: telegram
        isPaused: false
      - uid: instance_swap_out_of_space
        title: Instance Swap Out Of Space
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: '(1 - (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes)) * 100 > 90'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 2m
        annotations:
          summary: "Swap memory has less than 10% space left"
          description: "Swap memory has less than 10% space left\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        labels:
          severity: error
          receiver: telegram
        isPaused: false
      - uid: instance_network_receive_errors
        title: Instance Network Receive Errors
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: 'increase(node_network_receive_errs_total[2m]) > 10'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 1h
        annotations:
          summary: "Network interface '{{ $labels.device }}' is reporting many receive errors"
          description: '{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} receive errors in the last two minutes.'
        labels:
          severity: error
          receiver: telegram
        isPaused: false
      - uid: instance_network_transmit_errors
        title: Instance Network Transmit Errors
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: 'increase(node_network_transmit_errs_total[2m]) > 10'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 1h
        annotations:
          summary: "Network interface '{{ $labels.device }}' is reporting many transmit errors"
          description: '{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} transmit errors in the last two minutes.'
        labels:
          severity: error
          receiver: telegram
        isPaused: false
      - uid: high_number_conntrack
        title: Instance High Number Conntrack Entries Used
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: '(node_nf_conntrack_entries / node_nf_conntrack_entries_limit) > 0.75'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 0m
        annotations:
          summary: "Number of conntrack are getting close to the limit"
          description: "{{ $value | humanizePercentage }} of conntrack entries are used"
        labels:
          severity: error
          receiver: telegram
        isPaused: false
      - uid: instance_clock_skew_detected
        title: Instance Clock Skew Detected
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: '((node_timex_offset_seconds > 0.05 and deriv(node_timex_offset_seconds[5m]) >= 0) or (node_timex_offset_seconds < -0.05 and deriv(node_timex_offset_seconds[5m]) <= 0))'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 10m
        annotations:
          summary: "Host clock skew"
          description: "Clock skew detected. Clock is out of sync. Ensure NTP is configured correctly on this host.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        labels:
          severity: error
          receiver: telegram
        isPaused: false
      - uid: instance_clock_not_synchronising
        title: Instance Clock Not Synchronising
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: '(min_over_time(node_timex_sync_status[1m]) == 0 and node_timex_maxerror_seconds >= 16)'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 20m
        annotations:
          summary: "Host clock not synchronising"
          description: "Clock on {{ $labels.instance }} is not synchronising. Ensure NTP is configured on this host."
        labels:
          severity: error
          receiver: telegram
        isPaused: false
      - uid: host_out_of_inodes
        title: Host Out Of Inodes
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: '(node_filesystem_files_free / node_filesystem_files < .10 and ON (instance, device, mountpoint) node_filesystem_readonly == 0)'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 2m
        annotations:
          summary: "Host out of inodes"
          description: "Disk is almost running out of available inodes (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        labels:
          severity: error
          receiver: telegram
        isPaused: false
      - uid: host_inodes_may_fill_in_24_hours
        title: Host Inodes May Fill In 24 Hours
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: 'predict_linear(node_filesystem_files_free{fstype!~"^(fuse.*|tmpfs|cifs|nfs)"}[1h], 86400) <= 0 and node_filesystem_files_free > 0'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 2m
        annotations:
          summary: "Host inodes may fill in 24 hours"
          description: "Filesystem will likely run out of inodes within the next 24 hours at current write rate\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        labels:
          severity: warn
          receiver: telegram
        isPaused: false
      - uid: host_filesystem_device_error
        title: Host Filesystem Device Error
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: 'node_filesystem_device_error{fstype!~"^(fuse.*|tmpfs|cifs|nfs)",mountpoint!="/boot/efi"} == 1'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 2m
        annotations:
          summary: "Host filesystem device error"
          description: "Error stat-ing the {{ $labels.mountpoint }} filesystem\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        labels:
          severity: error
          receiver: telegram
        isPaused: false
      - uid: host_unusual_disk_read_latency
        title: Host Unusual Disk Read Latency
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: '(rate(node_disk_read_time_seconds_total[1m]) / rate(node_disk_reads_completed_total[1m]) > 0.1 and rate(node_disk_reads_completed_total[1m]) > 0)'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 2m
        annotations:
          summary: "Host unusual disk read latency"
          description: "Disk latency is growing (read operations > 100ms)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        labels:
          severity: warn
          receiver: telegram
        isPaused: false
      - uid: host_unusual_disk_write_latency
        title: Host Unusual Disk Write Latency
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: '(rate(node_disk_write_time_seconds_total[1m]) / rate(node_disk_writes_completed_total[1m]) > 0.1 and rate(node_disk_writes_completed_total[1m]) > 0)'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 2m
        annotations:
          summary: "Host unusual disk write latency"
          description: "Disk latency is growing (write operations > 100ms)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        labels:
          severity: warn
          receiver: telegram
        isPaused: false
      - uid: host_cpu_high_iowait
        title: Host CPU High Iowait
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: 'avg by (instance) (rate(node_cpu_seconds_total{mode="iowait"}[5m])) > .10'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 0m
        annotations:
          summary: "Host CPU high iowait"
          description: "CPU iowait > 10%. Your CPU is idling waiting for storage to respond.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        labels:
          severity: error
          receiver: telegram
        isPaused: false
      - uid: host_unusual_disk_io
        title: Host Unusual Disk IO
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: 'rate(node_disk_io_time_seconds_total[5m]) > 0.8'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 5m
        annotations:
          summary: "Host unusual disk IO"
          description: "Disk usage >80%. Check storage for issues or increase IOPS capabilities. Check storage for issues.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        labels:
          severity: error
          receiver: telegram
        isPaused: false
      - uid: host_systemd_service_crashed
        title: Host Systemd Service Crashed
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: '(node_systemd_unit_state{state="failed"} == 1)'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 0m
        annotations:
          summary: "Host systemd service crashed"
          description: "systemd service crashed\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        labels:
          severity: error
          receiver: telegram
        isPaused: false
      - uid: host_kernel_version_deviations
        title: Host Kernel Version Deviations
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: 'changes(node_uname_info[1h]) > 0'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 0m
        annotations:
          summary: "Host kernel version deviations"
          description: "Kernel version for {{ $labels.instance }} has changed.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        labels:
          severity: warn
          receiver: telegram
        isPaused: false
      - uid: host_oom_kill_detected
        title: Host OOM Kill Detected
        condition: A
        data:
          - refId: A
            datasourceUid: DS_PROMETHEUS
            relativeTimeRange:
              from: 600
              to: 0
            model:
              expr: '(increase(node_vmstat_oom_kill[1m]) > 0)'
              instant: true
              intervalMs: 1000
              maxDataPoints: 43200
              refId: A
        dashboardUid: node-exporter-full
        noDataState: OK
        execErrState: Alerting
        for: 0m
        annotations:
          summary: "Host OOM kill detected"
          description: "OOM kill detected\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        labels:
          severity: error
          receiver: telegram
        isPaused: false
